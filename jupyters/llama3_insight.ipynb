{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'"
   ],
   "id": "eec9d520e1a68c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import (\n",
    "    LlamaForCausalLM,\n",
    "    pipeline,\n",
    "    AutoTokenizer,\n",
    "    LlamaModel,\n",
    "    LlamaConfig, Qwen2VLForConditionalGeneration\n",
    ")\n",
    "import transformers\n",
    "import json\n",
    "from safetensors.torch import save_file\n",
    "import torch\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import HuggingFacePipeline"
   ],
   "id": "70c68da45ce734dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model_dir = \"/data/Models/llama3_8B_Base\"",
   "id": "543ceceb088f2a84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, truncation=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "# tokenizer(\"Microservice Resource Provision is Improtant to Quality of Service and Energy Conservation\")\n",
    "tokenizer(\"Please clarify the importantce of diverse resource provision policies on microservice quality of service and run-time energy conservation.\")"
   ],
   "id": "15057f0879482f1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    " LLM_model = LlamaForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    load_in_8bit=False,\n",
    "    device_map='auto',\n",
    ")\n",
    "base_model = LLM_model"
   ],
   "id": "f93414620e49ef84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# pipe = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=LLM_model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     max_length=256,\n",
    "#     temperature=0.05,\n",
    "#     top_p=0.9,\n",
    "#     repetition_penalty=1\n",
    "# )\n",
    "\n",
    "# task_agent = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# orchestrator_agent_prompt_template = \"\"\"\n",
    "# You are an expert in wireless communication developed by Nokia Bell Labs China. Below is a query that describes a task of communication. Please give your response.\n",
    "# ### Queryï¼š\n",
    "# {query}\n",
    "# ### Response:\n",
    "# \"\"\"\n",
    "# orchestrator_prompt_template = PromptTemplate(template=orchestrator_agent_prompt_template, input_variables=[\"query\"])\n",
    "# OrchestratorAgent = LLMChain(prompt=orchestrator_prompt_template, llm=task_agent)\n",
    "# orchestrator_out = OrchestratorAgent.run(query=q)"
   ],
   "id": "2934c5c89bcad35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "LLM_model.model.config",
   "id": "cb263bafb6d7a1a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "LLM_model.lm_head\n",
    "# LLM_model.get_input_embeddings"
   ],
   "id": "afe4cd22191cbfdd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "llama3_l0 = LLM_model.model.layers[0]",
   "id": "b5a8278d5dc05a53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for item in LLM_model.state_dict():\n",
    "    print(f\"{item}:                             {LLM_model.state_dict()[item].shape}\")"
   ],
   "id": "622502eff2aefdb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for i in range(0, 4):\n",
    "    save_file(LLM_model.model.layers[i].state_dict(), f\"llama3_l{i}.safetensors\")"
   ],
   "id": "3b3fb4774d6e09f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "LLM_model.model.layers[1]",
   "id": "fa6f51c19d3df321"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "LLM_model.model.layers[-1].self_attn",
   "id": "c5dee7c3b65eebb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# pipeline = transformers.pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model_dir,\n",
    "#     model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "#     device_map=\"auto\",\n",
    "#     max_length=128,\n",
    "# )\n",
    "# pipeline(\"Show me a story about thief\")"
   ],
   "id": "c9e78b0b4606ac83"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "be2d73ba10095ba4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
