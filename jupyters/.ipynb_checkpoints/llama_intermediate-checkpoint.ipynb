{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fdf5f17-3238-4847-a281-3546f9f3a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "522be91f-d248-49d8-8f0c-994c6c1a790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from transformers import (\n",
    "    LlamaForCausalLM,\n",
    "    pipeline,\n",
    "    AutoTokenizer,AutoModelForCausalLM,\n",
    "    LlamaModel,\n",
    "    LlamaConfig, Qwen2VLForConditionalGeneration\n",
    ")\n",
    "import transformers\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db19b33e-f29a-43c8-ac5f-23bb070ef6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/data/Models/llama3_8B_Base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd4f719-34c0-4133-8288-091ead1a1b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.31s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, truncation=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    load_in_8bit=False,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map='auto',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb0ff5d0-b5f0-4bff-92fe-f02884cbf4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = LlamaForCausalLM.from_pretrained(\n",
    "#     model_dir,\n",
    "#     load_in_8bit=False,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     device_map='auto',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04c36d89-c60d-4d60-9fb6-8f719a28581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_outputs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "392fef1c-9536-4bae-b454-a936e11e5828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_func(module, inputs, outputs, layer_idx):\n",
    "    intermediate_outputs[layer_idx] = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf0c6faa-15eb-429d-bec5-1417e186d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx, layer in enumerate(base_model.model.layers):\n",
    "    layer.register_forward_hook(\n",
    "        lambda m, inp, out, idx=layer_idx: hook_func(m, inp, out, idx)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed4188f6-4f0e-49cb-b5d3-2eb771d26992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[128000,   1090,  48945,  26639,  19816,    311,    757,    323,    279,\n",
      "           1917,    627,    791,   3907,    315,   8421,    520,  19816,    374,\n",
      "            832,    315,    279,   7140,    753,   1948,    586,   3495,  23978,\n",
      "             13,  11699,    220,   8652,     11,    931,   5496,  52121,    527,\n",
      "           4315,    279,   1455,   6992,    304,    279,   3224,     11,    449,\n",
      "            220,   1419,  48078,  67185,    988,     11,    220,    605,  96815,\n",
      "          32293,  26526,     11,    220,    508,  69522,     11,    323,    220,\n",
      "            966,  90386,     13,  26639,  19816,    374,    279,   7928,  19683,\n",
      "            304,  10913,   8421,    323,    279,   2132,   7928,  19683,    304,\n",
      "            279,   1614,    315,   8421,     13,    578,  12374,    753,    220,\n",
      "           1135,     11,    931,   4236,   4097,    682,    220,   1135,   5415,\n",
      "            323,    810,   1109,    220,   4364,   5961,     13,  26639,  19816,\n",
      "            753,    220,    972,  31252,    323,   8853,   3085,    810,   1109,\n",
      "            220,   8258,  41534,   8547,   7620,    323,    810,   1109,    220,\n",
      "           1049,  19560]], device='cuda:0')\n",
      "Introduce UT Austin to me and the world.\n",
      "The University of Texas at Austin is one of the nation’s top public research universities. Its 350,000 living alumni are among the most successful in the country, with 23 Nobel laureates, 10 Pulitzer Prize winners, 20 astronauts, and 30 billionaires. UT Austin is the largest employer in Central Texas and the second largest employer in the state of Texas. The university’s 50,000 students represent all 50 states and more than 120 countries. UT Austin’s 18 colleges and schools offer more than 170 undergraduate degree programs and more than 200 graduate\n"
     ]
    }
   ],
   "source": [
    "question = \"Introduce UT Austin to me\"\n",
    "\n",
    "inputs = tokenizer(question, return_tensors='pt').to(base_model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    response = base_model.generate(inputs.input_ids, max_length=128)\n",
    "# print(response)\n",
    "print(tokenizer.decode(response.cpu()[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7944dce3-6b61-41b2-991a-13b1577dd94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: tensor([[[-0.0054,  0.0009, -0.0085,  ..., -0.0395, -0.0085,  0.0023]]],\n",
      "       device='cuda:0')\n",
      "Layer 1: tensor([[[ 0.0049, -0.0160, -0.0189,  ..., -0.0559, -0.0005, -0.0228]]],\n",
      "       device='cuda:0')\n",
      "Layer 2: tensor([[[-0.0174,  0.0031, -0.0147,  ..., -0.0787,  0.0015, -0.0359]]],\n",
      "       device='cuda:0')\n",
      "Layer 3: tensor([[[-0.0130, -0.0050,  0.0040,  ..., -0.0734,  0.0544, -0.0444]]],\n",
      "       device='cuda:0')\n",
      "Layer 4: tensor([[[-0.0123,  0.0572, -0.0531,  ..., -0.0158,  0.0014, -0.0059]]],\n",
      "       device='cuda:0')\n",
      "Layer 5: tensor([[[-0.0070,  0.0397, -0.0099,  ..., -0.0195,  0.0215,  0.0083]]],\n",
      "       device='cuda:0')\n",
      "Layer 6: tensor([[[-0.0150,  0.0191, -0.0455,  ..., -0.0181, -0.0199, -0.0355]]],\n",
      "       device='cuda:0')\n",
      "Layer 7: tensor([[[-0.0310, -0.0370, -0.0976,  ..., -0.0115, -0.0040,  0.0397]]],\n",
      "       device='cuda:0')\n",
      "Layer 8: tensor([[[ 0.0183,  0.0240, -0.0645,  ..., -0.0727, -0.0157,  0.0606]]],\n",
      "       device='cuda:0')\n",
      "Layer 9: tensor([[[-0.0796, -0.0622, -0.0741,  ..., -0.0812, -0.0673,  0.0733]]],\n",
      "       device='cuda:0')\n",
      "Layer 10: tensor([[[-0.0816, -0.0689, -0.0126,  ..., -0.1102, -0.1000,  0.0002]]],\n",
      "       device='cuda:0')\n",
      "Layer 11: tensor([[[-0.0797, -0.0431, -0.0263,  ..., -0.1074, -0.0265,  0.0776]]],\n",
      "       device='cuda:0')\n",
      "Layer 12: tensor([[[-0.0055, -0.0234,  0.0612,  ..., -0.1073,  0.0181,  0.0937]]],\n",
      "       device='cuda:0')\n",
      "Layer 13: tensor([[[ 0.0024,  0.0042,  0.0350,  ..., -0.1386,  0.0422,  0.1711]]],\n",
      "       device='cuda:0')\n",
      "Layer 14: tensor([[[ 0.0687,  0.0269, -0.0341,  ..., -0.1827,  0.1990,  0.1665]]],\n",
      "       device='cuda:1')\n",
      "Layer 15: tensor([[[ 0.0217,  0.0357, -0.0225,  ..., -0.1393,  0.1312,  0.2715]]],\n",
      "       device='cuda:1')\n",
      "Layer 16: tensor([[[ 0.0095,  0.0463, -0.0875,  ..., -0.1169,  0.1192,  0.2152]]],\n",
      "       device='cuda:1')\n",
      "Layer 17: tensor([[[ 0.0700,  0.0409, -0.1176,  ..., -0.1515,  0.0242,  0.3531]]],\n",
      "       device='cuda:1')\n",
      "Layer 18: tensor([[[ 0.0418, -0.0546, -0.2681,  ..., -0.3875,  0.0394,  0.3887]]],\n",
      "       device='cuda:1')\n",
      "Layer 19: tensor([[[ 0.0421, -0.0717, -0.4448,  ..., -0.3409,  0.1756,  0.3996]]],\n",
      "       device='cuda:1')\n",
      "Layer 20: tensor([[[ 0.0389, -0.1535, -0.3789,  ..., -0.3921,  0.1622,  0.3727]]],\n",
      "       device='cuda:1')\n",
      "Layer 21: tensor([[[ 0.1779, -0.1009, -0.4358,  ..., -0.4059,  0.1296,  0.3974]]],\n",
      "       device='cuda:1')\n",
      "Layer 22: tensor([[[ 0.2549, -0.0427, -0.3118,  ..., -0.3333,  0.1553,  0.3867]]],\n",
      "       device='cuda:1')\n",
      "Layer 23: tensor([[[ 0.3686, -0.1682, -0.2325,  ..., -0.4465,  0.1230,  0.5095]]],\n",
      "       device='cuda:1')\n",
      "Layer 24: tensor([[[ 0.3231, -0.1365, -0.3270,  ..., -0.3999,  0.0578,  0.2742]]],\n",
      "       device='cuda:1')\n",
      "Layer 25: tensor([[[ 0.2880, -0.0676, -0.1437,  ..., -0.1987,  0.1264,  0.4397]]],\n",
      "       device='cuda:1')\n",
      "Layer 26: tensor([[[ 0.2938,  0.1662, -0.2002,  ..., -0.1287,  0.1112,  0.3114]]],\n",
      "       device='cuda:1')\n",
      "Layer 27: tensor([[[ 0.5352,  0.0275, -0.0372,  ..., -0.2149,  0.3005,  0.3821]]],\n",
      "       device='cuda:1')\n",
      "Layer 28: tensor([[[ 0.3851,  0.1098,  0.1994,  ..., -0.1993,  0.4264,  0.3291]]],\n",
      "       device='cuda:1')\n",
      "Layer 29: tensor([[[ 0.4287,  0.0475,  0.3326,  ..., -0.2471,  0.4145,  0.4077]]],\n",
      "       device='cuda:1')\n",
      "Layer 30: tensor([[[ 0.2764, -0.3461,  0.0854,  ..., -0.4259,  0.5518,  0.2889]]],\n",
      "       device='cuda:1')\n",
      "Layer 31: tensor([[[ 0.2305, -0.4087, -0.1990,  ..., -0.0177,  0.3538,  0.5821]]],\n",
      "       device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "for layer_idx, tensor in intermediate_outputs.items():\n",
    "    print(f\"Layer {layer_idx}: {tensor[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e6dd1c-b755-4f95-850b-08ff5c6f6175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM_model = LlamaForCausalLM.from_pretrained(\n",
    "#     model_dir,\n",
    "#     load_in_8bit=False,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     device_map='auto',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05ade840-c222-429a-9fca-a23be6f14c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.27it/s]\n"
     ]
    }
   ],
   "source": [
    "LLM_model = LlamaForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    load_in_8bit=False,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map='auto',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
