{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from transformers import (\n",
    "    LlamaForCausalLM,\n",
    "    pipeline,\n",
    "    AutoTokenizer,AutoModelForCausalLM,\n",
    "    LlamaModel,AutoModel,\n",
    "    LlamaConfig, Qwen2VLForConditionalGeneration,\n",
    "    BertTokenizer, BertModel\n",
    ")\n",
    "import transformers\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import HuggingFacePipeline"
   ],
   "id": "e53ab3340ebedaa6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_dir = \"/data/Models/bert-base-cased\"\n",
    "dataset_dir = \"/data/Datasets/nyu-mll_glue\""
   ],
   "id": "a319bf3b317c7415"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_dir = \"/data/Models/bert-large-cased\"\n",
    "dataset_dir = \"/data/Datasets/nyu-mll_glue\""
   ],
   "id": "6412b4b61fc3c67f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 加载 GLUE 数据集，默认为 'sst2' 任务，可以换成其他任务如 'mnli'、'qqp' 等\n",
    "dataset = load_dataset(dataset_dir, \"cola\")\n",
    "# 获取测试集\n",
    "test_set = dataset[\"test\"]\n",
    "# 打印测试集的前10条数据\n",
    "# test_set\n",
    "# for i in range(10):\n",
    "#     print(test_set[i])\n",
    "test_sentences = [test_set[i]['sentence'] for i in range(30)]\n",
    "# test_sentences"
   ],
   "id": "d49bb28588ed33ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "intermediate_outputs = {}",
   "id": "dde8e73bb4543f23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def hook_func(module, inputs, outputs, layer_idx):\n",
    "    intermediate_outputs[layer_idx] = outputs[0]"
   ],
   "id": "4761244850b0c4ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
    "bert_model = BertModel.from_pretrained(\n",
    "    model_dir,\n",
    ")"
   ],
   "id": "c843815a41fd745f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "bert_model.config",
   "id": "8d0a8a0a9fb4c1d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for layer_idx, layer in enumerate(bert_model.encoder.layer):\n",
    "    layer.register_forward_hook(\n",
    "        lambda m, inp, out, idx=layer_idx: hook_func(m, inp, out, idx)\n",
    "    )"
   ],
   "id": "737103f6ea1f1fb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "text = \"Replace me by any text you'd like.\"\n",
    "# test_sentences = [\n",
    "#     \"Replace me by any text you'd like.\",\n",
    "#     \"One apple one day, keep the doctor away\",\n",
    "#     \"What is the captial of China\"\n",
    "# ]\n",
    "input_ids = tokenizer(test_sentences, padding=True, truncation=True, return_tensors=\"pt\").input_ids\n",
    "# input_ids\n",
    "# output = model(**encoded_input)"
   ],
   "id": "2f09c23e05561827"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with torch.no_grad():\n",
    "    bert_out = bert_model(input_ids)\n",
    "# bert_out"
   ],
   "id": "1e92496494dca78a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# for layer_idx, tensor in intermediate_outputs.items():\n",
    "#     print(f\"Layer {layer_idx}: {tensor.shape}\")"
   ],
   "id": "88d41e6a0a1c46c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "intermediate_outputs[0][:,0,:].shape",
   "id": "1eb39286a189f043"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(bert_model.encoder.layer)",
   "id": "b7d0bd8c2746fa4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Zero-dimension Persistent Homology",
   "id": "f20e2eae11528d6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import scipy.spatial.distance as dist\n",
    "import gudhi as gd\n",
    "import matplotlib.pyplot as plt\n",
    "from persim import plot_diagrams\n",
    "from ripser import ripser\n",
    "from ripser import Rips\n",
    "import persim"
   ],
   "id": "ad6ba9e5385c19c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Zero-dimension Persistent Homology Official Implement",
   "id": "7ea70c2fd2c80a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_rf_vr(pm_data):\n",
    "    rips = Rips(maxdim=2)\n",
    "    dgm = rips.fit_transform(pm_data)\n",
    "    H0 = dgm[0][:-1]\n",
    "    if len(H0) > 1:\n",
    "        r_f = np.max(H0[:, 1])  # 取最大的死亡时间（即最小连通分量合并半径）\n",
    "    else:\n",
    "        r_f = 0  # 如果只有一个分量，说明已经连通\n",
    "    return r_f, dgm"
   ],
   "id": "1560e25d8aedcd4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pm_data = np.array(intermediate_outputs[0][:,0,:])\n",
    "\n",
    "# Instantiate Vietoris-Rips solver\n",
    "rips = Rips(maxdim=2)\n",
    "dgm = rips.fit_transform( pm_data)\n",
    "\n",
    "plt.figure(figsize=(5, 5), dpi=80)\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "persim.plot_diagrams(dgm, title=\"Persistence Diagram\")\n",
    "# print(f\"rips.r_cover_ is ... {rips.r_cover_}\")\n",
    "# plt.savefig(\"homology_example_persistence-diagram.png\", dpi='figure', format=None, metadata=None,\n",
    "#         bbox_inches=None, pad_inches=0.1,\n",
    "#         facecolor='white', edgecolor='auto')"
   ],
   "id": "6c2d38b3bb406453"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "r_f_list = []\n",
    "for layer_idx, tensor in intermediate_outputs.items():\n",
    "    # 计算最小半径\n",
    "    r_f, _ = compute_rf_vr(tensor[:, 0, :])\n",
    "    r_f_list.append(r_f)\n",
    "    # print(f\"Layer {layer_idx} -- radis -- {r_f}\")"
   ],
   "id": "8f6d32c0cd71bacb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#---------------------------------------------------------------------------------------------------\n",
    "p_num = len(bert_model.encoder.layer)\n",
    "x = np.linspace(0, p_num, 1)  # 在 0 到 10 之间生成 100 个等间距的点\n",
    "x = np.arange(p_num)\n",
    "y = r_f_list  \n",
    "\n",
    "plt.plot(x, y, label=\"BERT-Large\", color='b', linestyle='-')\n",
    "plt.scatter(x, y, color='r', marker='o')\n",
    "plt.title(\"Zero-dimension Persistent Homology\")\n",
    "plt.xlabel(\"Layers\")\n",
    "plt.ylabel(\"Radius\")\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "9bc7352ee4488995"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ChatGPT-based VR complex computation",
   "id": "612b297f65ce5605"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# def compute_min_radius_vr(vectors):\n",
    "#     \"\"\"\n",
    "#     计算基于 Vietoris-Rips 复形，使所有向量最终合并为一个连通分量的最小半径 r_f。\n",
    "#     \"\"\"\n",
    "#     # 计算欧几里得距离矩阵\n",
    "#     distance_matrix = dist.pdist(vectors, metric='euclidean')\n",
    "    \n",
    "#     # 转换为方阵形式\n",
    "#     distance_matrix = dist.squareform(distance_matrix)\n",
    "    \n",
    "#     # 构造 VR 复形\n",
    "#     rips_complex = gd.RipsComplex(distance_matrix=distance_matrix)\n",
    "#     simplex_tree = rips_complex.create_simplex_tree(max_dimension=1)\n",
    "    \n",
    "#     # 获取所有 1-维单纯形（边）的死亡时间，即当它们形成连通分量时的最大半径\n",
    "#     edges = [simplex for simplex in simplex_tree.get_filtration() if len(simplex[0]) == 2]\n",
    "#     # 找到形成单一连通分量的最小半径 r_f\n",
    "#     r_f = max(edge[1] for edge in edges)\n",
    "#     return r_f"
   ],
   "id": "70258cb99940455b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# r_f_list = []\n",
    "# for layer_idx, tensor in intermediate_outputs.items():\n",
    "#     # 计算最小半径\n",
    "#     r_f = compute_min_radius_vr(tensor[:, 0, :])\n",
    "#     r_f_list.append(r_f)\n",
    "#     # print(f\"Layer {layer_idx} -- radis -- {r_f}\")\n",
    "    \n",
    "# #---------------------------------------------------------------------------------------------------\n",
    "# p_num = len(bert_model.encoder.layer)\n",
    "# x = np.linspace(0, p_num, 1)  # 在 0 到 10 之间生成 100 个等间距的点\n",
    "# x = np.arange(p_num)\n",
    "# y = r_f_list  \n",
    "\n",
    "# plt.plot(x, y, label=\"BERT-Base\", color='b', linestyle='-')\n",
    "# plt.scatter(x, y, color='r', marker='o')\n",
    "# plt.title(\"Zero-dimension Persistent Homology\")\n",
    "# plt.xlabel(\"Layers\")\n",
    "# plt.ylabel(\"Radius\")\n",
    "\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ],
   "id": "59191516daecf647"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# points = intermediate_outputs[0][:,0,:]\n",
    "\n",
    "# distance_matrix = dist.squareform(dist.pdist(points, metric='euclidean'))\n",
    "# # 构造 VR 复形\n",
    "# rips_complex = gd.RipsComplex(distance_matrix=distance_matrix)\n",
    "# simplex_tree = rips_complex.create_simplex_tree(max_dimension=1)\n",
    "\n",
    "# # 获取所有 1-维单纯形（边）的死亡时间，即当它们形成连通分量时的最大半径\n",
    "# edges = [simplex for simplex in simplex_tree.get_filtration() if len(simplex[0]) == 2]\n",
    "# homology = np.array([(0, edge[1]) for edge in edges])\n",
    "# # 找到形成单一连通分量的最小半径 r_f\n",
    "# r_f = max(edge[1] for edge in edges)\n",
    "\n",
    "# print(f\"Vietoris-Rips 复形计算的最小连通半径 r_f: {r_f:.4f}\")\n",
    "\n",
    "# # 绘制 Birth-Death 持续同调图\n",
    "# # plt.figure(figsize=(8, 6))\n",
    "# plot_diagrams([homology], show=True, title=\"0-Persistent Homology Birth-Death Diagram\")\n",
    "# # plt.axhline(y=r_f, color='r', linestyle='--', label=f\"r_f = {r_f:.4f}\")\n",
    "# # plt.legend()\n",
    "# # plt.show()\n",
    "# homology"
   ],
   "id": "fdb722d030c49a53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# points = intermediate_outputs[0][:,0,:]\n",
    "\n",
    "# distance_matrix = dist.squareform(dist.pdist(points, metric='euclidean'))\n",
    "# result = ripser(distance_matrix, maxdim=0, distance_matrix=True, metric='euclidean')\n",
    "# diagrams = result['dgms']  # 获取生死图数据\n",
    "# plot_diagrams(diagrams, show=True)\n",
    "\n",
    "# min_connect_radius=np.max(diagrams[0][:, 1])\n",
    "# min_connect_radius"
   ],
   "id": "b49eb9a4672cb2af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1f978037456398f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
