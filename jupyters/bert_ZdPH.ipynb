{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "522be91f-d248-49d8-8f0c-994c6c1a790b",
   "metadata": {},
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from transformers import (\n",
    "    LlamaForCausalLM,\n",
    "    pipeline,\n",
    "    AutoTokenizer,AutoModelForCausalLM,\n",
    "    LlamaModel,AutoModel,\n",
    "    LlamaConfig, Qwen2VLForConditionalGeneration,\n",
    "    BertTokenizer, BertModel\n",
    ")\n",
    "import transformers\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import HuggingFacePipeline"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5324362d-1ee9-4b47-988c-22e77bd01542",
   "metadata": {},
   "source": [
    "model_dir = \"/data/Models/bert-base-cased\"\n",
    "dataset_dir = \"/data/Datasets/nyu-mll_glue\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7cf2126-3656-43ce-9e62-acd3f753f3a2",
   "metadata": {},
   "source": [
    "model_dir = \"/data/Models/bert-large-cased\"\n",
    "dataset_dir = \"/data/Datasets/nyu-mll_glue\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3f0cb00-b04a-472a-9953-0072deab8ab4",
   "metadata": {},
   "source": [
    "# 加载 GLUE 数据集，默认为 'sst2' 任务，可以换成其他任务如 'mnli'、'qqp' 等\n",
    "dataset = load_dataset(dataset_dir, \"cola\")\n",
    "# 获取测试集\n",
    "test_set = dataset[\"test\"]\n",
    "# 打印测试集的前10条数据\n",
    "# test_set\n",
    "# for i in range(10):\n",
    "#     print(test_set[i])\n",
    "test_sentences = [test_set[i]['sentence'] for i in range(10)]\n",
    "test_sentences"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f68077b9-8ca0-40ed-8c93-cba67ea5a115",
   "metadata": {},
   "source": [
    "intermediate_outputs = {}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c14ca772-0a28-4ba1-9de8-274b12aadac4",
   "metadata": {},
   "source": [
    "def hook_func(module, inputs, outputs, layer_idx):\n",
    "    intermediate_outputs[layer_idx] = outputs[0]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abde5a3b-3605-45fe-be3d-848efc1ca7a9",
   "metadata": {},
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
    "bert_model = BertModel.from_pretrained(model_dir)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e83d20c1-b4cb-429e-a04e-d595991c2878",
   "metadata": {},
   "source": [
    "for layer_idx, layer in enumerate(bert_model.encoder.layer):\n",
    "    layer.register_forward_hook(\n",
    "        lambda m, inp, out, idx=layer_idx: hook_func(m, inp, out, idx)\n",
    "    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c327f99-0c01-454c-8e0d-1d469946fcb5",
   "metadata": {},
   "source": [
    "text = \"Replace me by any text you'd like.\"\n",
    "# test_sentences = [\n",
    "#     \"Replace me by any text you'd like.\",\n",
    "#     \"One apple one day, keep the doctor away\",\n",
    "#     \"What is the captial of China\"\n",
    "# ]\n",
    "input_ids = tokenizer(test_sentences, padding=True, truncation=True, return_tensors=\"pt\").input_ids\n",
    "input_ids\n",
    "# output = model(**encoded_input)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b98c613-6c41-4e71-9cdd-9ec61dc99696",
   "metadata": {},
   "source": [
    "with torch.no_grad():\n",
    "    bert_out = bert_model(input_ids)\n",
    "# bert_out"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5d101ac-ba47-4df0-a3b6-3926c8b0a06b",
   "metadata": {},
   "source": [
    "for layer_idx, tensor in intermediate_outputs.items():\n",
    "    print(f\"Layer {layer_idx}: {tensor.shape}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7436749-82b2-4134-b88b-efe2085220e4",
   "metadata": {},
   "source": [
    "intermediate_outputs[0][:,0,:].shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed786bec-2d3d-41f5-982a-4c1c8a34814e",
   "metadata": {},
   "source": [
    "len(bert_model.encoder.layer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3c39c23f-eede-4929-80b5-d86aa43025cf",
   "metadata": {},
   "source": [
    "## Zero-dimension Persistent Homology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ae5c565-e1ac-4788-b141-1228d0b7e67f",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import scipy.spatial.distance as dist\n",
    "import gudhi as gd\n",
    "import matplotlib.pyplot as plt\n",
    "from persim import plot_diagrams\n",
    "from ripser import ripser\n",
    "from ripser import Rips\n",
    "import persim"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bffaaf1e-2f32-4b00-8795-967226d61de7",
   "metadata": {},
   "source": [
    "## Zero-dimension Persistent Homology Official Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47d79bfe-4480-4c25-91fc-8717baa350ed",
   "metadata": {},
   "source": [
    "def compute_rf_vr(pm_data):\n",
    "    rips = Rips(maxdim=2)\n",
    "    dgm = rips.fit_transform(pm_data)\n",
    "    H0 = dgm[0][:-1]\n",
    "    if len(H0) > 1:\n",
    "        r_f = np.max(H0[:, 1])  # 取最大的死亡时间（即最小连通分量合并半径）\n",
    "    else:\n",
    "        r_f = 0  # 如果只有一个分量，说明已经连通\n",
    "    return r_f, dgm"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "513ccf5e-14b4-40f6-9129-716bc46c13f5",
   "metadata": {},
   "source": [
    "pm_data = np.array(intermediate_outputs[0][:,0,:])\n",
    "\n",
    "# Instantiate Vietoris-Rips solver\n",
    "rips = Rips(maxdim=2)\n",
    "dgm = rips.fit_transform( pm_data)\n",
    "\n",
    "plt.figure(figsize=(5, 5), dpi=80)\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "persim.plot_diagrams(dgm, title=\"Persistence Diagram\")\n",
    "# print(f\"rips.r_cover_ is ... {rips.r_cover_}\")\n",
    "# plt.savefig(\"homology_example_persistence-diagram.png\", dpi='figure', format=None, metadata=None,\n",
    "#         bbox_inches=None, pad_inches=0.1,\n",
    "#         facecolor='white', edgecolor='auto')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cb4b8f7-c546-4c7c-aa06-1e862da1c0b0",
   "metadata": {},
   "source": [
    "r_f_list = []\n",
    "for layer_idx, tensor in intermediate_outputs.items():\n",
    "    # 计算最小半径\n",
    "    r_f, _ = compute_rf_vr(tensor[:, 0, :])\n",
    "    r_f_list.append(r_f)\n",
    "    # print(f\"Layer {layer_idx} -- radis -- {r_f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8905aa28-9a29-4a0f-bf28-29bc5adceb35",
   "metadata": {},
   "source": [
    "#---------------------------------------------------------------------------------------------------\n",
    "p_num = len(bert_model.encoder.layer)\n",
    "x = np.linspace(0, p_num, 1)  # 在 0 到 10 之间生成 100 个等间距的点\n",
    "x = np.arange(p_num)\n",
    "y = r_f_list  \n",
    "\n",
    "plt.plot(x, y, label=\"BERT-Large\", color='b', linestyle='-')\n",
    "plt.scatter(x, y, color='r', marker='o')\n",
    "plt.title(\"Zero-dimension Persistent Homology\")\n",
    "plt.xlabel(\"Layers\")\n",
    "plt.ylabel(\"Radius\")\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "19762521-fe06-468c-9029-965ca0e41cb5",
   "metadata": {},
   "source": [
    "## ChatGPT-based VR complex computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0ff1698-71c2-4552-863c-bca3161598a1",
   "metadata": {},
   "source": [
    "def compute_min_radius_vr(vectors):\n",
    "    \"\"\"\n",
    "    计算基于 Vietoris-Rips 复形，使所有向量最终合并为一个连通分量的最小半径 r_f。\n",
    "    \"\"\"\n",
    "    # 计算欧几里得距离矩阵\n",
    "    distance_matrix = dist.pdist(vectors, metric='euclidean')\n",
    "    \n",
    "    # 转换为方阵形式\n",
    "    distance_matrix = dist.squareform(distance_matrix)\n",
    "    \n",
    "    # 构造 VR 复形\n",
    "    rips_complex = gd.RipsComplex(distance_matrix=distance_matrix)\n",
    "    simplex_tree = rips_complex.create_simplex_tree(max_dimension=1)\n",
    "    \n",
    "    # 获取所有 1-维单纯形（边）的死亡时间，即当它们形成连通分量时的最大半径\n",
    "    edges = [simplex for simplex in simplex_tree.get_filtration() if len(simplex[0]) == 2]\n",
    "    # 找到形成单一连通分量的最小半径 r_f\n",
    "    r_f = max(edge[1] for edge in edges)\n",
    "    return r_f"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e431e38-2a6b-4f5a-907b-dfe527bfb892",
   "metadata": {},
   "source": [
    "r_f_list = []\n",
    "for layer_idx, tensor in intermediate_outputs.items():\n",
    "    # 计算最小半径\n",
    "    r_f = compute_min_radius_vr(tensor[:, 0, :])\n",
    "    r_f_list.append(r_f)\n",
    "    # print(f\"Layer {layer_idx} -- radis -- {r_f}\")\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------------\n",
    "p_num = len(bert_model.encoder.layer)\n",
    "x = np.linspace(0, p_num, 1)  # 在 0 到 10 之间生成 100 个等间距的点\n",
    "x = np.arange(p_num)\n",
    "y = r_f_list  \n",
    "\n",
    "plt.plot(x, y, label=\"BERT-Base\", color='b', linestyle='-')\n",
    "plt.scatter(x, y, color='r', marker='o')\n",
    "plt.title(\"Zero-dimension Persistent Homology\")\n",
    "plt.xlabel(\"Layers\")\n",
    "plt.ylabel(\"Radius\")\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ca92c75-07c0-49de-a224-c05b88b51b2f",
   "metadata": {},
   "source": [
    "points = intermediate_outputs[0][:,0,:]\n",
    "\n",
    "distance_matrix = dist.squareform(dist.pdist(points, metric='euclidean'))\n",
    "# 构造 VR 复形\n",
    "rips_complex = gd.RipsComplex(distance_matrix=distance_matrix)\n",
    "simplex_tree = rips_complex.create_simplex_tree(max_dimension=1)\n",
    "\n",
    "# 获取所有 1-维单纯形（边）的死亡时间，即当它们形成连通分量时的最大半径\n",
    "edges = [simplex for simplex in simplex_tree.get_filtration() if len(simplex[0]) == 2]\n",
    "homology = np.array([(0, edge[1]) for edge in edges])\n",
    "# 找到形成单一连通分量的最小半径 r_f\n",
    "r_f = max(edge[1] for edge in edges)\n",
    "\n",
    "print(f\"Vietoris-Rips 复形计算的最小连通半径 r_f: {r_f:.4f}\")\n",
    "\n",
    "# 绘制 Birth-Death 持续同调图\n",
    "# plt.figure(figsize=(8, 6))\n",
    "plot_diagrams([homology], show=True, title=\"0-Persistent Homology Birth-Death Diagram\")\n",
    "# plt.axhline(y=r_f, color='r', linestyle='--', label=f\"r_f = {r_f:.4f}\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "homology"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5f7ce0a-0500-485d-8eeb-f487c4dc9ab7",
   "metadata": {},
   "source": [
    "points = intermediate_outputs[0][:,0,:]\n",
    "\n",
    "distance_matrix = dist.squareform(dist.pdist(points, metric='euclidean'))\n",
    "result = ripser(distance_matrix, maxdim=0, distance_matrix=True, metric='euclidean')\n",
    "diagrams = result['dgms']  # 获取生死图数据\n",
    "plot_diagrams(diagrams, show=True)\n",
    "\n",
    "min_connect_radius=np.max(diagrams[0][:, 1])\n",
    "min_connect_radius"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7a30f7-0003-41b7-8735-3f0908b893a2",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
